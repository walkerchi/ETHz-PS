{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive \n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/walkerchi/Physics-Seminar.git\n",
    "!pwd\n",
    "!ls\n",
    "%cd Physics-Seminar/\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import timeit\n",
    "\n",
    "    \n",
    "class UQ_PINN:\n",
    "    # Initialize the class\n",
    "    def __init__(self, X_u, X_b, Y_u, X_f, layers_P_u, layers_P_k, layers_Q, layers_T, lam = 1.5, beta = 1.0, q = 1, u_0 = - 10.):\n",
    "                \n",
    "        # Normalize data\n",
    "        self.lb = np.array([0.0, 0.0])\n",
    "        self.ub = np.array([10.0, 10.0])\n",
    "        self.lbb = np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "        self.ubb = np.array([10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0])\n",
    "        X_u = (X_u - self.lb) - 0.5*(self.ub - self.lb)\n",
    "        X_b = (X_b - self.lbb) - 0.5*(self.ubb - self.lbb)\n",
    "        X_f = (X_f - self.lb) - 0.5*(self.ub - self.lb)\n",
    "\n",
    "\n",
    "        self.q = q\n",
    "        self.u_0 = u_0\n",
    "        self.ksat = 10.\n",
    "        \n",
    "        self.x1_u = X_u[:,0:1] # dimension  N_u x 1\n",
    "        self.x2_u = X_u[:,1:2] # dimension  N_u x 1\n",
    "        self.y_u = Y_u           # dimension N_u\n",
    "\n",
    "        self.x1_f = X_f[:,0:1]   # dimension N_f x 1\n",
    "        self.x2_f = X_f[:,1:2]   # dimension N_f x 1\n",
    "\n",
    "        # Position of the boundary \n",
    "        self.x1_b1 = X_b[:,0:1]\n",
    "        self.x2_b1 = X_b[:,1:2]\n",
    "        self.x1_b2 = X_b[:,2:3]\n",
    "        self.x2_b2 = X_b[:,3:4]\n",
    "        self.x1_b3 = X_b[:,4:5]\n",
    "        self.x2_b3 = X_b[:,5:6]\n",
    "        self.x1_b4 = X_b[:,6:7]\n",
    "        self.x2_b4 = X_b[:,7:8]\n",
    "        \n",
    "        # Layers of the neural networks\n",
    "        self.layers_P_u = layers_P_u\n",
    "        self.layers_Q = layers_Q\n",
    "        self.layers_T = layers_T\n",
    "        self.layers_P_k = layers_P_k   \n",
    "\n",
    "        # Dimensions of the inputs, outputs, latent variables \n",
    "        self.X_dim = self.x1_u.shape[1]\n",
    "        self.Y_u_dim = self.y_u.shape[1]\n",
    "        self.Y_k_dim = self.y_u.shape[1]\n",
    "        self.Y_f_dim = self.y_u.shape[1]\n",
    "        self.Z_dim = layers_Q[-1]\n",
    "\n",
    "        # Regularization parameters\n",
    "        self.lam = lam\n",
    "        self.beta = beta\n",
    "\n",
    "        # Ratio of training for generator and discriminator\n",
    "        self.k1 = 1\n",
    "        self.k2 = 5\n",
    "\n",
    "        # Initialize network weights and biases        \n",
    "        self.weights_P_u, self.biases_P_u = self.initialize_NN(layers_P_u)\n",
    "        self.weights_Q, self.biases_Q = self.initialize_NN(layers_Q)\n",
    "        self.weights_T, self.biases_T = self.initialize_NN(layers_T)\n",
    "        self.weights_P_k, self.biases_P_k = self.initialize_NN(layers_P_k)\n",
    "        \n",
    "        # Define Tensorflow session\n",
    "        self.sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "        \n",
    "        # Define placeholders and computational graph\n",
    "        self.x1_u_tf = tf.placeholder(tf.float32, shape=(None, self.X_dim))\n",
    "        self.x2_u_tf = tf.placeholder(tf.float32, shape=(None, self.X_dim))\n",
    "        self.x1_f_tf = tf.placeholder(tf.float32, shape=(None, self.X_dim))\n",
    "        self.x2_f_tf = tf.placeholder(tf.float32, shape=(None, self.X_dim))\n",
    "        self.y_u_tf = tf.placeholder(tf.float32, shape=(None, self.Y_u_dim))\n",
    "        self.y_k_tf = tf.placeholder(tf.float32, shape=(None, self.Y_k_dim))\n",
    "        self.y_f_tf = tf.placeholder(tf.float32, shape=(None, self.Y_f_dim))\n",
    "\n",
    "        self.x1_b1_tf = tf.placeholder(tf.float32, shape=(None, self.X_dim))\n",
    "        self.x2_b1_tf = tf.placeholder(tf.float32, shape=(None, self.X_dim))\n",
    "        self.x1_b2_tf = tf.placeholder(tf.float32, shape=(None, self.X_dim))\n",
    "        self.x2_b2_tf = tf.placeholder(tf.float32, shape=(None, self.X_dim))\n",
    "        self.x1_b3_tf = tf.placeholder(tf.float32, shape=(None, self.X_dim))\n",
    "        self.x2_b3_tf = tf.placeholder(tf.float32, shape=(None, self.X_dim))\n",
    "        self.x1_b4_tf = tf.placeholder(tf.float32, shape=(None, self.X_dim))\n",
    "        self.x2_b4_tf = tf.placeholder(tf.float32, shape=(None, self.X_dim))\n",
    "\n",
    "        self.z_b1_tf = tf.placeholder(tf.float32, shape=(None, self.Z_dim))\n",
    "        self.z_b2_tf = tf.placeholder(tf.float32, shape=(None, self.Z_dim))\n",
    "        self.z_b3_tf = tf.placeholder(tf.float32, shape=(None, self.Z_dim))\n",
    "        self.z_b4_tf = tf.placeholder(tf.float32, shape=(None, self.Z_dim))\n",
    "        self.z_u_tf = tf.placeholder(tf.float32, shape=(None, self.Z_dim))\n",
    "        self.z_f_tf = tf.placeholder(tf.float32, shape=(None, self.Z_dim))\n",
    "\n",
    "        self.y_u_pred = self.net_P_u(self.x1_u_tf, self.x2_u_tf, self.z_u_tf)\n",
    "        self.y_b1_pred = self.get_b1(self.x1_b1_tf, self.x2_b1_tf, self.z_b1_tf)\n",
    "        self.y_b2_pred = self.get_b2(self.x1_b2_tf, self.x2_b2_tf, self.z_b2_tf)\n",
    "        self.y_b3_pred = self.get_b3(self.x1_b3_tf, self.x2_b3_tf, self.z_b3_tf)\n",
    "        self.y_b4_pred = self.get_b4(self.x1_b4_tf, self.x2_b4_tf, self.z_b4_tf)\n",
    "        self.y_k_pred = self.net_P_k(self.y_u_pred)\n",
    "        self.y_f_pred = self.get_f(self.x1_f_tf, self.x2_f_tf, self.z_f_tf)\n",
    "\n",
    "        # Generator loss (to be minimized)\n",
    "        self.G_loss, self.KL_loss, self.recon_loss, self.PDE_loss = self.compute_generator_loss(self.x1_u_tf, self.x2_u_tf,\n",
    "                                                                            self.y_u_pred, self.y_f_pred, self.y_b1_pred, self.y_b2_pred, \n",
    "                                                                            self.y_b3_pred, self.y_b4_pred, self.z_u_tf)\n",
    "\n",
    "        # Discriminator loss (to be minimized)\n",
    "        self.T_loss  = self.compute_discriminator_loss(self.x1_u_tf, self.x2_u_tf, self.y_u_tf, self.z_u_tf)\n",
    "\n",
    "        # Define optimizer        \n",
    "        self.optimizer_KL = tf.train.AdamOptimizer(1e-4)\n",
    "        self.optimizer_T = tf.train.AdamOptimizer(1e-4)\n",
    "        \n",
    "        # Define train Ops\n",
    "        self.train_op_KL = self.optimizer_KL.minimize(self.G_loss, \n",
    "                                                      var_list = [self.weights_P_u, self.biases_P_u, self.weights_P_k, self.biases_P_k,\n",
    "                                                                  self.weights_Q, self.biases_Q])\n",
    "                                                                    \n",
    "        self.train_op_T = self.optimizer_T.minimize(self.T_loss,\n",
    "                                                    var_list = [self.weights_T, self.biases_T])\n",
    "\n",
    "        # Initialize Tensorflow variables\n",
    "        init = tf.global_variables_initializer()\n",
    "        self.sess.run(init)\n",
    "\n",
    "    \n",
    "    # Initialize network weights and biases using Xavier initialization\n",
    "    def initialize_NN(self, layers):      \n",
    "        # Xavier initialization\n",
    "        def xavier_init(size):\n",
    "            in_dim = size[0]\n",
    "            out_dim = size[1]\n",
    "            xavier_stddev = 1. / np.sqrt((in_dim + out_dim) / 2.)\n",
    "            return tf.Variable(tf.random_normal([in_dim, out_dim], dtype=tf.float32) * xavier_stddev, dtype=tf.float32)   \n",
    "        \n",
    "        weights = []\n",
    "        biases = []\n",
    "        num_layers = len(layers) \n",
    "        for l in range(0,num_layers-1):\n",
    "            W = xavier_init(size=[layers[l], layers[l+1]])\n",
    "            b = tf.Variable(tf.zeros([1,layers[l+1]], dtype=tf.float32), dtype=tf.float32)\n",
    "            weights.append(W)\n",
    "            biases.append(b)        \n",
    "        return weights, biases\n",
    "           \n",
    "           \n",
    "    # Evaluates the forward pass\n",
    "    def forward_pass(self, H, layers, weights, biases):\n",
    "        num_layers = len(layers)\n",
    "        for l in range(0,num_layers-2):\n",
    "            W = weights[l]\n",
    "            b = biases[l]\n",
    "            H = tf.tanh(tf.add(tf.matmul(H, W), b))\n",
    "        W = weights[-1]\n",
    "        b = biases[-1]\n",
    "        H = tf.add(tf.matmul(H, W), b)\n",
    "        return H\n",
    "    \n",
    "    def f(self, X_normalized):\n",
    "        return tf.zeros_like(X_normalized) \n",
    "\n",
    "    # Decoder: p(y|x,z)\n",
    "    def net_P_u(self, X1, X2, Z):\n",
    "        Y = self.forward_pass(tf.concat([X1, X2, Z], 1),\n",
    "                              self.layers_P_u,\n",
    "                              self.weights_P_u,\n",
    "                              self.biases_P_u)\n",
    "        return Y\n",
    "    \n",
    "    # Encoder: q(z|x,y)\n",
    "    def net_Q(self, X1, X2, Y):\n",
    "        Z = self.forward_pass(tf.concat([X1, X2, Y], 1),\n",
    "                              self.layers_Q,\n",
    "                              self.weights_Q,\n",
    "                              self.biases_Q)\n",
    "        return Z\n",
    "    \n",
    "    # Discriminator\n",
    "    def net_T(self, X1, X2, Y):\n",
    "        T = self.forward_pass(tf.concat([X1, X2, Y], 1),\n",
    "                              self.layers_T,\n",
    "                              self.weights_T,\n",
    "                              self.biases_T)        \n",
    "        return T\n",
    "    \n",
    "    # Decoder: p(y|x,z)\n",
    "    def net_P_k(self, U):\n",
    "        Y = self.forward_pass(U,\n",
    "                              self.layers_P_k,\n",
    "                              self.weights_P_k,\n",
    "                              self.biases_P_k)\n",
    "        return self.ksat * tf.exp(Y)\n",
    "    \n",
    "\n",
    "    def get_u(self, X1, X2, Z):\n",
    "        z_prior = Z       \n",
    "        u = self.net_P_u(X1, X2, z_prior)\n",
    "        return u\n",
    "\n",
    "    def get_k(self, U):   \n",
    "        u = self.net_P_k(U)\n",
    "        return u    \n",
    "\n",
    "    def get_b1(self, X1, X2, Z):   \n",
    "        z_prior = Z       \n",
    "        u = self.net_P_u(X1, X2, z_prior)\n",
    "        u_x1 = tf.gradients(u, X1)[0]\n",
    "        k = self.net_P_k(u)\n",
    "        temp = self.q + k * u_x1\n",
    "        return temp\n",
    "\n",
    "    def get_b2(self, X1, X2, Z):   \n",
    "        z_prior = Z       \n",
    "        u = self.net_P_u(X1, X2, z_prior)\n",
    "        u_x2 = tf.gradients(u, X2)[0]\n",
    "        return u_x2\n",
    "\n",
    "    def get_b3(self, X1, X2, Z):   \n",
    "        z_prior = Z       \n",
    "        u = self.net_P_u(X1, X2, z_prior)\n",
    "        temp = u - self.u_0\n",
    "        return temp\n",
    "\n",
    "    def get_b4(self, X1, X2, Z):   \n",
    "        z_prior = Z       \n",
    "        u = self.net_P_u(X1, X2, z_prior)\n",
    "        u_x2 = tf.gradients(u, X2)[0]\n",
    "        return u_x2\n",
    "\n",
    "    def get_f(self, X1, X2, Z_u):\n",
    "        u = self.net_P_u(X1, X2, Z_u)\n",
    "        k = self.net_P_k(u)\n",
    "        u_x1 = tf.gradients(u, X1)[0]\n",
    "        u_x2 = tf.gradients(u, X2)[0]\n",
    "        f_1 = tf.gradients(k*u_x1, X1)[0]\n",
    "        f_2 = tf.gradients(k*u_x2, X2)[0]\n",
    "        f = f_1 + f_2\n",
    "        return f\n",
    "    \n",
    "    def compute_generator_loss(self, x1_u, x2_u, y_u_pred, y_f_pred, y_b1_pred, y_b2_pred, y_b3_pred, y_b4_pred, z_u):    \n",
    "        # Encoder: q(z|x,y)\n",
    "        z_u_prior = z_u\n",
    "\n",
    "        z_u_encoder = self.net_Q(x1_u, x2_u, y_u_pred)\n",
    "\n",
    "        y_u_pred = self.net_P_u(x1_u, x2_u, z_u)\n",
    "        T_pred = self.net_T(x1_u, x2_u, y_u_pred)\n",
    "\n",
    "        # KL-divergence between the data and the generator samples\n",
    "        KL = tf.reduce_mean(T_pred)\n",
    "        \n",
    "        # Entropic regularization\n",
    "        log_q = - tf.reduce_mean(tf.square(z_u_prior-z_u_encoder))\n",
    "\n",
    "        # Physics-informed loss\n",
    "        loss_f = tf.reduce_mean(tf.square(y_f_pred)) + tf.reduce_mean(tf.square(y_b1_pred)) +\\\n",
    "                tf.reduce_mean(tf.square(y_b2_pred)) +  tf.reduce_mean(tf.square(y_b3_pred)) + tf.reduce_mean(tf.square(y_b4_pred))\n",
    "\n",
    "        # Generator loss\n",
    "        loss = KL + (1.0-self.lam)*log_q + self.beta * loss_f\n",
    "        \n",
    "        return loss, KL, (1.0-self.lam)*log_q, self.beta * loss_f\n",
    "    \n",
    "    \n",
    "    def compute_discriminator_loss(self, X1, X2, Y, Z): \n",
    "        # Prior: p(z)\n",
    "        z_prior = Z\n",
    "        # Decoder: p(y|x,z)\n",
    "        Y_pred = self.net_P_u(X1, X2, z_prior)                \n",
    "        \n",
    "        # Discriminator loss\n",
    "        T_real = self.net_T(X1, X2, Y)\n",
    "        T_fake = self.net_T(X1, X2, Y_pred)\n",
    "        \n",
    "        T_real = tf.sigmoid(T_real)\n",
    "        T_fake = tf.sigmoid(T_fake)\n",
    "        \n",
    "        T_loss = -tf.reduce_mean(tf.log(1.0 - T_real + 1e-8) + \\\n",
    "                                 tf.log(T_fake + 1e-8)) \n",
    "        \n",
    "        return T_loss\n",
    "\n",
    "    # Trains the model\n",
    "    def train(self, nIter = 20000): \n",
    "\n",
    "        start_time = timeit.default_timer()\n",
    "        for it in range(nIter):     \n",
    "\n",
    "            # Sampling from latent spaces\n",
    "            z_u = np.random.randn(self.x1_u.shape[0], self.Z_dim)\n",
    "            z_f = np.random.randn(self.x1_f.shape[0], self.Z_dim)\n",
    "            z_b1 = np.random.randn(self.x1_b1.shape[0], self.Z_dim)\n",
    "            z_b2 = np.random.randn(self.x1_b2.shape[0], self.Z_dim)\n",
    "            z_b3 = np.random.randn(self.x1_b3.shape[0], self.Z_dim)\n",
    "            z_b4 = np.random.randn(self.x1_b4.shape[0], self.Z_dim)\n",
    "\n",
    "            # Define a dictionary for associating placeholders with data\n",
    "            tf_dict = {self.x1_u_tf: self.x1_u, self.x2_u_tf: self.x2_u, self.x1_f_tf: self.x1_f, self.x2_f_tf: self.x2_f, \n",
    "                    self.y_u_tf: self.y_u, self.x1_b1_tf: self.x1_b1, self.x2_b1_tf: self.x2_b1, self.x1_b2_tf: self.x1_b2, self.x2_b2_tf: self.x2_b2,\n",
    "                    self.x1_b3_tf: self.x1_b3, self.x2_b3_tf: self.x2_b3, self.x1_b4_tf: self.x1_b4, self.x2_b4_tf: self.x2_b4, \n",
    "                    self.z_u_tf: z_u, self.z_f_tf: z_f, self.z_b1_tf: z_b1, self.z_b2_tf: z_b2, self.z_b3_tf: z_b3, self.z_b4_tf: z_b4}\n",
    "            \n",
    "            # Run the Tensorflow session to minimize the loss\n",
    "            for i in range(self.k1):\n",
    "                self.sess.run(self.train_op_T, tf_dict)\n",
    "            for j in range(self.k2):\n",
    "                self.sess.run(self.train_op_KL, tf_dict)\n",
    "            \n",
    "            # Print\n",
    "            if it % 100 == 0:\n",
    "                elapsed = timeit.default_timer() - start_time\n",
    "                loss_KL_value, reconv, loss_PDE = self.sess.run([self.KL_loss, self.recon_loss, self.PDE_loss], tf_dict)\n",
    "                loss_T_value = self.sess.run(self.T_loss, tf_dict)\n",
    "                print('It: %d, KL_loss: %.2e, Recon_loss: %.2e, PDE_loss: %.2e, T_loss: %.2e, Time: %.2f' % \n",
    "                      (it, loss_KL_value, reconv, loss_PDE, loss_T_value, elapsed))\n",
    "                start_time = timeit.default_timer()\n",
    "                \n",
    "\n",
    "    # Evaluates predictions at test points           \n",
    "    def predict_k(self, X_star): \n",
    "        # Center around the origin\n",
    "        X_star = (X_star - self.lb) - 0.5*(self.ub - self.lb)\n",
    "        # Predict \n",
    "        z_u = np.random.randn(X_star.shape[0], self.Z_dim)    \n",
    "        tf_dict = {self.x1_u_tf: X_star[:,0:1], self.x2_u_tf: X_star[:,1:2], self.z_u_tf: z_u}    \n",
    "        k_star = self.sess.run(self.y_k_pred, tf_dict) \n",
    "        return k_star / self.ksat\n",
    "    \n",
    "    # Evaluates predictions at test points           \n",
    "    def predict_u(self, X_star): \n",
    "        # Center around the origin\n",
    "        X_star = (X_star - self.lb) - 0.5*(self.ub - self.lb)\n",
    "        # Predict   \n",
    "        z_u = np.random.randn(X_star.shape[0], self.Z_dim)       \n",
    "        tf_dict = {self.x1_u_tf: X_star[:,0:1], self.x2_u_tf: X_star[:,1:2], self.z_u_tf: z_u}      \n",
    "        u_star = self.sess.run(self.y_u_pred, tf_dict) \n",
    "        return u_star\n",
    "    \n",
    "    # Evaluates predictions at test points           \n",
    "    def predict_f(self, X_star): \n",
    "        # Center around the origin\n",
    "        X_star = (X_star - self.lb) - 0.5*(self.ub - self.lb)\n",
    "        # Predict      \n",
    "        z_f = np.random.randn(X_star.shape[0], self.Z_dim) \n",
    "        tf_dict = {self.x1_f_tf: X_star[:,0:1], self.x2_f_tf: X_star[:,1:2], self.z_f_tf: z_f}     \n",
    "        f_star = self.sess.run(self.y_f_pred, tf_dict) \n",
    "        return f_star\n",
    "\n",
    "    # Predict the k as function of u\n",
    "    def predict_k_from_u(self, u):\n",
    "        tf_dict = {self.y_u_pred: u}\n",
    "        k_star = self.sess.run(self.y_k_pred, tf_dict) \n",
    "        return k_star / self.ksat\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "#mpl.use('pgf')\n",
    "\n",
    "def figsize(scale, nplots = 1):\n",
    "    fig_width_pt = 390.0                          # Get this from LaTeX using \\the\\textwidth\n",
    "    inches_per_pt = 1.0/72.27                       # Convert pt to inch\n",
    "    golden_mean = (np.sqrt(5.0)-1.0)/2.0            # Aesthetic ratio (you could change this)\n",
    "    fig_width = fig_width_pt*inches_per_pt*scale    # width in inches\n",
    "    fig_height = nplots*fig_width*golden_mean              # height in inches\n",
    "    fig_size = [fig_width,fig_height]\n",
    "    return fig_size\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# I make my own newfig and savefig functions\n",
    "def newfig(width, nplots = 1):\n",
    "    fig = plt.figure(figsize=figsize(width, nplots))\n",
    "    ax = fig.add_subplot(111)\n",
    "    return fig, ax\n",
    "\n",
    "def savefig(filename, crop = True):\n",
    "    if crop == True:\n",
    "#        plt.savefig('{}.pgf'.format(filename), bbox_inches='tight', pad_inches=0)\n",
    "        plt.savefig('{}.pdf'.format(filename), bbox_inches='tight', pad_inches=0)\n",
    "        plt.savefig('{}.eps'.format(filename), bbox_inches='tight', pad_inches=0)\n",
    "    else:\n",
    "#        plt.savefig('{}.pgf'.format(filename))\n",
    "        plt.savefig('{}.pdf'.format(filename))\n",
    "        plt.savefig('{}.eps'.format(filename))\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import scipy.io\n",
    "from scipy.interpolate import griddata\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import time\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "\n",
    "\n",
    "# Load the data\n",
    "data = np.load('equations/Darcy/nonlinear2d_data.npz')\n",
    "X = data['X']\n",
    "K = data['k']\n",
    "U = data['u']\n",
    "\n",
    "# Exact relation between k and u\n",
    "def k_vanGenuchten(u):\n",
    "    alpha = 0.1\n",
    "    n = 1.885\n",
    "    m = 1.0 - 1.0/n\n",
    "    s = (1.0 + (alpha*np.abs(u))**n)**(-m)\n",
    "    k = np.sqrt(s)*(1.0 - (1.0 - s**(1.0/m))**m)**2\n",
    "    return k\n",
    "\n",
    "N = 10000\n",
    "N_f = N\n",
    "N_u = 1000\n",
    "N_b = 100 # for one boundary\n",
    "\n",
    "X_dim = 1 \n",
    "Y_dim = 1\n",
    "Z_dim = 2\n",
    "\n",
    "L1 = 10.\n",
    "L2 = 10.\n",
    "noise = 0.05\n",
    "\n",
    "X_u = np.zeros((N_u,2))\n",
    "Y_u = np.zeros((N_u,1))\n",
    "X_f = np.zeros((N_f,2))\n",
    "\n",
    "# Boundary points\n",
    "# -K(u) du(x1, x2) / dx1 = q              x1 = 0\n",
    "x1_b1 = np.zeros(N_b)[:,None]\n",
    "x2_b1 = L2 * np.random.random(N_b)[:,None]\n",
    "X_b1 = np.hstack((x1_b1, x2_b1))\n",
    "# du(x1, x2)/dx2 = 0                      x2 = 0\n",
    "x1_b2 = L1 * np.random.random(N_b)[:,None]\n",
    "x2_b2 = np.zeros(N_b)[:,None]\n",
    "X_b2 = np.hstack((x1_b2, x2_b2))\n",
    "# u(x1, x2) = u0                          x1 = L1\n",
    "x1_b3 = L1 * np.ones(N_b)[:,None]\n",
    "x2_b3 = L2 * np.random.random(N_b)[:,None]\n",
    "X_b3 = np.hstack((x1_b3, x2_b3))   \n",
    "# du(x1, x2)/dx2 = 0                      x2 = L2e\n",
    "x1_b4 = L1 * np.random.random(N_b)[:,None]\n",
    "x2_b4 = L2 * np.ones(N_b)[:,None]\n",
    "X_b4 = np.hstack((x1_b4, x2_b4))\n",
    "X_b = np.hstack((X_b1, X_b2))\n",
    "X_b = np.hstack((X_b, X_b3))\n",
    "X_b = np.hstack((X_b, X_b4))\n",
    "\n",
    "# Collocation points\n",
    "X1_f = L1 * np.random.random(N_f)[:,None]\n",
    "X2_f = L2 * np.random.random(N_f)[:,None]\n",
    "X_f = np.hstack((X1_f, X2_f))\n",
    "\n",
    "U_data = U\n",
    "X_data = X\n",
    "\n",
    "idx_u = np.random.choice(N, N_u, replace=False)\n",
    "for i in range(N_u):\n",
    "    X_u[i,:] = X_data[idx_u[i],:]\n",
    "    Y_u[i,:] = U_data[idx_u[i]]\n",
    "\n",
    "# Corrupt the training data by noise\n",
    "Y_u = Y_u + noise * np.std(Y_u) * np.random.randn(N_u,Y_dim)\n",
    "# Model creation\n",
    "layers_P_u = np.array([X_dim+X_dim+Z_dim,50,50,50,50,Y_dim])\n",
    "layers_Q = np.array([X_dim+X_dim+Y_dim,50,50,50,50,Z_dim])  \n",
    "layers_T = np.array([X_dim+X_dim+Y_dim,50,50,50,1])\n",
    "layers_P_k = np.array([Y_dim,50,50,50,50,Y_dim])\n",
    "\n",
    "model = UQ_PINN(X_u, X_b, Y_u, X_f, layers_P_u, layers_P_k, layers_Q, layers_T, lam = 1.5, beta = 1.0, q = 1., u_0 = - 10.)\n",
    "\n",
    "model.train(nIter = 30000)\n",
    "\n",
    "\n",
    "X_star = X\n",
    "k_star = K.T\n",
    "u_star = U.T\n",
    "\n",
    "# Domain bounds\n",
    "lb, ub = X.min(0), X.max(0)\n",
    "# Plot\n",
    "nn = 200\n",
    "x = np.linspace(lb[0], ub[0], nn)\n",
    "y = np.linspace(lb[1], ub[1], nn)\n",
    "XX, YY = np.meshgrid(x,y)\n",
    "\n",
    "K_plot = griddata(X_star, k_star.flatten(), (XX, YY), method='cubic')\n",
    "U_plot = griddata(X_star, u_star.flatten(), (XX, YY), method='cubic')\n",
    "\n",
    "\n",
    "N_samples = 500\n",
    "kkk = np.zeros((X_star.shape[0], N_samples))\n",
    "uuu = np.zeros((X_star.shape[0], N_samples))\n",
    "fff = np.zeros((X_star.shape[0], N_samples))\n",
    "for i in range(0, N_samples):\n",
    "    kkk[:,i:i+1] = model.predict_k(X_star)\n",
    "    uuu[:,i:i+1] = model.predict_u(X_star)\n",
    "    fff[:,i:i+1] = model.predict_f(X_star)\n",
    "\n",
    "np.save('uuu5.npy', uuu)\n",
    "np.save('kkk5.npy', kkk)\n",
    "    \n",
    "kkk_mu_pred = np.mean(kkk, axis = 1)\n",
    "kkk_Sigma_pred = np.var(kkk, axis = 1)\n",
    "uuu_mu_pred = np.mean(uuu, axis = 1)    \n",
    "uuu_Sigma_pred = np.var(uuu, axis = 1)\n",
    "fff_mu_pred = np.mean(fff, axis = 1)    \n",
    "fff_Sigma_pred = np.var(fff, axis = 1)\n",
    "\n",
    "\n",
    "K_mu_plot = griddata(X_star, kkk_mu_pred.flatten(), (XX, YY), method='cubic')\n",
    "U_mu_plot = griddata(X_star, uuu_mu_pred.flatten(), (XX, YY), method='cubic')\n",
    "F_mu_plot = griddata(X_star, fff_mu_pred.flatten(), (XX, YY), method='cubic')\n",
    "K_Sigma_plot = griddata(X_star, kkk_Sigma_pred.flatten(), (XX, YY), method='cubic')\n",
    "U_Sigma_plot = griddata(X_star, uuu_Sigma_pred.flatten(), (XX, YY), method='cubic')\n",
    "F_Sigma_plot = griddata(X_star, fff_Sigma_pred.flatten(), (XX, YY), method='cubic')\n",
    "\n",
    "\n",
    "fig = plt.figure(2,figsize=(12,12))\n",
    "plt.subplot(2,2,1)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.pcolor(XX, YY, K_plot, cmap='viridis')\n",
    "plt.colorbar().ax.tick_params(labelsize=15)\n",
    "plt.xlabel('$x_1$', fontsize=15)\n",
    "plt.ylabel('$x_2$', fontsize=15)  \n",
    "plt.title('Exact $k(x_1,x_2)$', fontsize=15)\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.pcolor(XX, YY, K_mu_plot, cmap='viridis')\n",
    "plt.colorbar().ax.tick_params(labelsize=15)\n",
    "plt.xlabel('$x_1$', fontsize=15)\n",
    "plt.ylabel('$x_2$', fontsize=15)  \n",
    "plt.title('Prediction $k(x_1,x_2)$', fontsize=15)\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.pcolor(XX, YY, np.abs(K_plot - K_mu_plot), cmap='viridis')\n",
    "plt.colorbar().ax.tick_params(labelsize=15)\n",
    "plt.xlabel('$x_1$', fontsize=15)\n",
    "plt.ylabel('$x_2$', fontsize=15)  \n",
    "plt.title('Error of $k(x_1,x_2)$', fontsize=15)\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.pcolor(XX, YY, np.abs(K_plot - K_mu_plot) / K_plot, cmap='viridis')\n",
    "plt.colorbar().ax.tick_params(labelsize=15)\n",
    "plt.xlabel('$x_1$', fontsize=15)\n",
    "plt.ylabel('$x_2$', fontsize=15)  \n",
    "plt.title('Relative error of $k(x_1,x_2)$', fontsize=15)\n",
    "plt.savefig('./reconstruction.png', dpi = 600)\n",
    "\n",
    "u = np.load('uuu5.npy')\n",
    "k = np.load('kkk5.npy')\n",
    "u_mu = np.mean(u, axis = 1)\n",
    "u = np.zeros((10000, 500))\n",
    "for i in range(500):\n",
    "    u[:,i] = u_mu\n",
    "    \n",
    "u = u.reshape(1,-1)\n",
    "k = k.reshape(1,-1)\n",
    "idx = np.random.choice(5000000, 1000, replace=False)\n",
    "u_p = u[:,idx]\n",
    "k_p = k[:,idx]\n",
    "\n",
    "\n",
    "\n",
    "u = np.linspace(-10.,-4., 1000)\n",
    "k = k_vanGenuchten(u)\n",
    "\n",
    "plt.figure(10, figsize=(6, 4))\n",
    "plt.xticks(fontsize=11)\n",
    "plt.yticks(fontsize=11)   \n",
    "plt.plot(u_p,k_p, 'bo') \n",
    "plt.plot(u,k, 'r-', label = \"Exact\", linewidth=2)\n",
    "ax = plt.gca()\n",
    "plt.xlabel('$u$',fontsize=11)\n",
    "plt.ylabel('$K(u)$',fontsize=11)\n",
    "plt.savefig('./UK.png', dpi = 600)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
